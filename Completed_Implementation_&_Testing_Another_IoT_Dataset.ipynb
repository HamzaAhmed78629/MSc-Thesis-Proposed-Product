{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrre2YGBPoOPHr2Yb+9CHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1efbdc439a804ba0a5ba5f0ea2d115d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_906e9908922243efa1255dc9f56200e9",
              "IPY_MODEL_194ccbe51b92438ca911794e9a97da55",
              "IPY_MODEL_6d60fd438eb94e48a28377e2eac3727d",
              "IPY_MODEL_210f9c45d3b742eb8aec3331a1e819c6",
              "IPY_MODEL_513c48528b9d41ddbf845d9afb366d66"
            ],
            "layout": "IPY_MODEL_a174b9fa4bb249818e042fabad904e57"
          }
        },
        "906e9908922243efa1255dc9f56200e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Load Data",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_81512f09b1b94e509d5a678105cd2c94",
            "style": "IPY_MODEL_abdb0afdd95547d6aa11cb2794af6114",
            "tooltip": ""
          }
        },
        "194ccbe51b92438ca911794e9a97da55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Check Compliance",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5e8247e29bf04bf8abf95a04a02d6c9f",
            "style": "IPY_MODEL_67923d04c9e249939e7dd1c7edd0b635",
            "tooltip": ""
          }
        },
        "6d60fd438eb94e48a28377e2eac3727d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "danger",
            "description": "Adjust Policies",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_120a45554d6c41fe9f7d86fec643e4bc",
            "style": "IPY_MODEL_2ba65c3152da4105947796b93fed0cc2",
            "tooltip": ""
          }
        },
        "210f9c45d3b742eb8aec3331a1e819c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Enforce Policies",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4a46451305bd4cf4965e235a38a3ef82",
            "style": "IPY_MODEL_ff22e6eb0e5c4d2fab9fd0e95feb1fe9",
            "tooltip": ""
          }
        },
        "513c48528b9d41ddbf845d9afb366d66": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c8762fc40d8d4d4ebe3a35be5e3dba94",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Loading data.....\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Dataset loaded successfully.\n",
                  "Displaying first few rows:\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "                     Unnamed: 0  id.orig_p  id.resp_p proto service  \\\ntime                                                                  \n2022-01-01 00:00:00           0      38667       1883   tcp    mqtt   \n2022-01-01 00:01:00           1      51143       1883   tcp    mqtt   \n2022-01-01 00:02:00           2      44761       1883   tcp    mqtt   \n2022-01-01 00:03:00           3      60893       1883   tcp    mqtt   \n2022-01-01 00:04:00           4      51087       1883   tcp    mqtt   \n\n                     flow_duration  fwd_pkts_tot  bwd_pkts_tot  \\\ntime                                                             \n2022-01-01 00:00:00      32.011598             9             5   \n2022-01-01 00:01:00      31.883584             9             5   \n2022-01-01 00:02:00      32.124053             9             5   \n2022-01-01 00:03:00      31.961063             9             5   \n2022-01-01 00:04:00      31.902362             9             5   \n\n                     fwd_data_pkts_tot  bwd_data_pkts_tot  ...  active.std  \\\ntime                                                       ...               \n2022-01-01 00:00:00                  3                  3  ...         0.0   \n2022-01-01 00:01:00                  3                  3  ...         0.0   \n2022-01-01 00:02:00                  3                  3  ...         0.0   \n2022-01-01 00:03:00                  3                  3  ...         0.0   \n2022-01-01 00:04:00                  3                  3  ...         0.0   \n\n                         idle.min      idle.max      idle.tot      idle.avg  \\\ntime                                                                          \n2022-01-01 00:00:00  2.972918e+07  2.972918e+07  2.972918e+07  2.972918e+07   \n2022-01-01 00:01:00  2.985528e+07  2.985528e+07  2.985528e+07  2.985528e+07   \n2022-01-01 00:02:00  2.984215e+07  2.984215e+07  2.984215e+07  2.984215e+07   \n2022-01-01 00:03:00  2.991377e+07  2.991377e+07  2.991377e+07  2.991377e+07   \n2022-01-01 00:04:00  2.981470e+07  2.981470e+07  2.981470e+07  2.981470e+07   \n\n                     idle.std  fwd_init_window_size  bwd_init_window_size  \\\ntime                                                                        \n2022-01-01 00:00:00       0.0                 64240                 26847   \n2022-01-01 00:01:00       0.0                 64240                 26847   \n2022-01-01 00:02:00       0.0                 64240                 26847   \n2022-01-01 00:03:00       0.0                 64240                 26847   \n2022-01-01 00:04:00       0.0                 64240                 26847   \n\n                     fwd_last_window_size   Attack_type  \ntime                                                     \n2022-01-01 00:00:00                   502  MQTT_Publish  \n2022-01-01 00:01:00                   502  MQTT_Publish  \n2022-01-01 00:02:00                   502  MQTT_Publish  \n2022-01-01 00:03:00                   502  MQTT_Publish  \n2022-01-01 00:04:00                   502  MQTT_Publish  \n\n[5 rows x 85 columns]",
                  "text/html": "\n  <div id=\"df-dc2e748b-9e49-4082-9a17-91238453ee5b\" class=\"colab-df-container\">\n    <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id.orig_p</th>\n      <th>id.resp_p</th>\n      <th>proto</th>\n      <th>service</th>\n      <th>flow_duration</th>\n      <th>fwd_pkts_tot</th>\n      <th>bwd_pkts_tot</th>\n      <th>fwd_data_pkts_tot</th>\n      <th>bwd_data_pkts_tot</th>\n      <th>...</th>\n      <th>active.std</th>\n      <th>idle.min</th>\n      <th>idle.max</th>\n      <th>idle.tot</th>\n      <th>idle.avg</th>\n      <th>idle.std</th>\n      <th>fwd_init_window_size</th>\n      <th>bwd_init_window_size</th>\n      <th>fwd_last_window_size</th>\n      <th>Attack_type</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-01 00:00:00</th>\n      <td>0</td>\n      <td>38667</td>\n      <td>1883</td>\n      <td>tcp</td>\n      <td>mqtt</td>\n      <td>32.011598</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.972918e+07</td>\n      <td>2.972918e+07</td>\n      <td>2.972918e+07</td>\n      <td>2.972918e+07</td>\n      <td>0.0</td>\n      <td>64240</td>\n      <td>26847</td>\n      <td>502</td>\n      <td>MQTT_Publish</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:01:00</th>\n      <td>1</td>\n      <td>51143</td>\n      <td>1883</td>\n      <td>tcp</td>\n      <td>mqtt</td>\n      <td>31.883584</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.985528e+07</td>\n      <td>2.985528e+07</td>\n      <td>2.985528e+07</td>\n      <td>2.985528e+07</td>\n      <td>0.0</td>\n      <td>64240</td>\n      <td>26847</td>\n      <td>502</td>\n      <td>MQTT_Publish</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:02:00</th>\n      <td>2</td>\n      <td>44761</td>\n      <td>1883</td>\n      <td>tcp</td>\n      <td>mqtt</td>\n      <td>32.124053</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.984215e+07</td>\n      <td>2.984215e+07</td>\n      <td>2.984215e+07</td>\n      <td>2.984215e+07</td>\n      <td>0.0</td>\n      <td>64240</td>\n      <td>26847</td>\n      <td>502</td>\n      <td>MQTT_Publish</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:03:00</th>\n      <td>3</td>\n      <td>60893</td>\n      <td>1883</td>\n      <td>tcp</td>\n      <td>mqtt</td>\n      <td>31.961063</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.991377e+07</td>\n      <td>2.991377e+07</td>\n      <td>2.991377e+07</td>\n      <td>2.991377e+07</td>\n      <td>0.0</td>\n      <td>64240</td>\n      <td>26847</td>\n      <td>502</td>\n      <td>MQTT_Publish</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:04:00</th>\n      <td>4</td>\n      <td>51087</td>\n      <td>1883</td>\n      <td>tcp</td>\n      <td>mqtt</td>\n      <td>31.902362</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.981470e+07</td>\n      <td>2.981470e+07</td>\n      <td>2.981470e+07</td>\n      <td>2.981470e+07</td>\n      <td>0.0</td>\n      <td>64240</td>\n      <td>26847</td>\n      <td>502</td>\n      <td>MQTT_Publish</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 85 columns</p>\n</div>\n    <div class=\"colab-df-buttons\">\n\n  <div class=\"colab-df-container\">\n    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc2e748b-9e49-4082-9a17-91238453ee5b')\"\n            title=\"Convert this dataframe to an interactive table.\"\n            style=\"display:none;\">\n\n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n  </svg>\n    </button>\n\n  <style>\n    .colab-df-container {\n      display:flex;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    .colab-df-buttons div {\n      margin-bottom: 4px;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n    <script>\n      const buttonEl =\n        document.querySelector('#df-dc2e748b-9e49-4082-9a17-91238453ee5b button.colab-df-convert');\n      buttonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n      async function convertToInteractive(key) {\n        const element = document.querySelector('#df-dc2e748b-9e49-4082-9a17-91238453ee5b');\n        const dataTable =\n          await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                    [key], {});\n        if (!dataTable) return;\n\n        const docLinkHtml = 'Like what you see? Visit the ' +\n          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n          + ' to learn more about interactive tables.';\n        element.innerHTML = '';\n        dataTable['output_type'] = 'display_data';\n        await google.colab.output.renderOutput(dataTable, element);\n        const docLink = document.createElement('div');\n        docLink.innerHTML = docLinkHtml;\n        element.appendChild(docLink);\n      }\n    </script>\n  </div>\n\n\n<div id=\"df-b51e4ca4-c571-4422-8183-8b33536414d6\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b51e4ca4-c571-4422-8183-8b33536414d6')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n\n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-b51e4ca4-c571-4422-8183-8b33536414d6 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>\n\n    </div>\n  </div>\n",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "dataframe"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Data is preprocessed successfully.\n",
                  "Target variable encoded.\n",
                  "Train-test split done successfully.\n",
                  "Training set size: 86181\n",
                  "Testing set size: 36936\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Reshaping data for CNN...\n",
                  "Data reshaped successfully.\n",
                  "Training CNN Model...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Epoch 1/5\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 27s - 10ms/step - accuracy: 0.9645 - loss: 0.1036 - val_accuracy: 0.9831 - val_loss: 0.0544\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Epoch 2/5\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 41s - 15ms/step - accuracy: 0.9851 - loss: 0.0480 - val_accuracy: 0.9897 - val_loss: 0.0354\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Epoch 3/5\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 25s - 9ms/step - accuracy: 0.9901 - loss: 0.0337 - val_accuracy: 0.9844 - val_loss: 0.0401\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Epoch 4/5\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 27s - 10ms/step - accuracy: 0.9915 - loss: 0.0276 - val_accuracy: 0.9928 - val_loss: 0.0263\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Epoch 5/5\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 24s - 9ms/step - accuracy: 0.9928 - loss: 0.0238 - val_accuracy: 0.9938 - val_loss: 0.0255\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "CNN Model trained successfully.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training LSTM Model...\n",
                  "Epoch 1/2\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 251s - 93ms/step - accuracy: 0.8202 - loss: 0.6590 - val_accuracy: 0.9249 - val_loss: 0.1857\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Epoch 2/2\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2694/2694 - 275s - 102ms/step - accuracy: 0.9244 - loss: 0.2289 - val_accuracy: 0.9125 - val_loss: 0.2061\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "LSTM Model trained successfully.\n"
                ]
              }
            ]
          }
        },
        "a174b9fa4bb249818e042fabad904e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81512f09b1b94e509d5a678105cd2c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdb0afdd95547d6aa11cb2794af6114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5e8247e29bf04bf8abf95a04a02d6c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67923d04c9e249939e7dd1c7edd0b635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "120a45554d6c41fe9f7d86fec643e4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba65c3152da4105947796b93fed0cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4a46451305bd4cf4965e235a38a3ef82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff22e6eb0e5c4d2fab9fd0e95feb1fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c8762fc40d8d4d4ebe3a35be5e3dba94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamzaAhmed78629/MSc-Thesis-Proposed-Product/blob/main/Completed_Implementation_%26_Testing_Another_IoT_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the required libraries\n",
        "!pip install pandas scikit-learn tensorflow python-docx ipywidgets\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukD-4BpBQO4w",
        "outputId": "f32cd954-5706-4855-f36b-4862d660c5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.9)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: python-docx, jedi\n",
            "Successfully installed jedi-0.19.1 python-docx-1.1.2\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7j0S0irQUpi",
        "outputId": "c788ab14-ae95-443d-dfe4-8683030745f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and inspecting the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/RT_IOT2022.csv\")\n",
        "\n",
        "# Printing the first few rows to inspect the structure and columns\n",
        "print(\"Dataset loaded. Displaying the first few rows:\\n\")\n",
        "print(data.head())\n",
        "\n",
        "# Printing column names\n",
        "print(\"\\nColumn names in the dataset:\")\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z22jLcMWT9cZ",
        "outputId": "1fe62a99-6aec-4270-aa28-4827afe204ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded. Displaying the first few rows:\n",
            "\n",
            "   Unnamed: 0  id.orig_p  id.resp_p proto service  flow_duration  \\\n",
            "0           0      38667       1883   tcp    mqtt      32.011598   \n",
            "1           1      51143       1883   tcp    mqtt      31.883584   \n",
            "2           2      44761       1883   tcp    mqtt      32.124053   \n",
            "3           3      60893       1883   tcp    mqtt      31.961063   \n",
            "4           4      51087       1883   tcp    mqtt      31.902362   \n",
            "\n",
            "   fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  ...  \\\n",
            "0             9             5                  3                  3  ...   \n",
            "1             9             5                  3                  3  ...   \n",
            "2             9             5                  3                  3  ...   \n",
            "3             9             5                  3                  3  ...   \n",
            "4             9             5                  3                  3  ...   \n",
            "\n",
            "   active.std      idle.min      idle.max      idle.tot      idle.avg  \\\n",
            "0         0.0  2.972918e+07  2.972918e+07  2.972918e+07  2.972918e+07   \n",
            "1         0.0  2.985528e+07  2.985528e+07  2.985528e+07  2.985528e+07   \n",
            "2         0.0  2.984215e+07  2.984215e+07  2.984215e+07  2.984215e+07   \n",
            "3         0.0  2.991377e+07  2.991377e+07  2.991377e+07  2.991377e+07   \n",
            "4         0.0  2.981470e+07  2.981470e+07  2.981470e+07  2.981470e+07   \n",
            "\n",
            "   idle.std  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \\\n",
            "0       0.0                 64240                 26847                   502   \n",
            "1       0.0                 64240                 26847                   502   \n",
            "2       0.0                 64240                 26847                   502   \n",
            "3       0.0                 64240                 26847                   502   \n",
            "4       0.0                 64240                 26847                   502   \n",
            "\n",
            "    Attack_type  \n",
            "0  MQTT_Publish  \n",
            "1  MQTT_Publish  \n",
            "2  MQTT_Publish  \n",
            "3  MQTT_Publish  \n",
            "4  MQTT_Publish  \n",
            "\n",
            "[5 rows x 85 columns]\n",
            "\n",
            "Column names in the dataset:\n",
            "Index(['Unnamed: 0', 'id.orig_p', 'id.resp_p', 'proto', 'service',\n",
            "       'flow_duration', 'fwd_pkts_tot', 'bwd_pkts_tot', 'fwd_data_pkts_tot',\n",
            "       'bwd_data_pkts_tot', 'fwd_pkts_per_sec', 'bwd_pkts_per_sec',\n",
            "       'flow_pkts_per_sec', 'down_up_ratio', 'fwd_header_size_tot',\n",
            "       'fwd_header_size_min', 'fwd_header_size_max', 'bwd_header_size_tot',\n",
            "       'bwd_header_size_min', 'bwd_header_size_max', 'flow_FIN_flag_count',\n",
            "       'flow_SYN_flag_count', 'flow_RST_flag_count', 'fwd_PSH_flag_count',\n",
            "       'bwd_PSH_flag_count', 'flow_ACK_flag_count', 'fwd_URG_flag_count',\n",
            "       'bwd_URG_flag_count', 'flow_CWR_flag_count', 'flow_ECE_flag_count',\n",
            "       'fwd_pkts_payload.min', 'fwd_pkts_payload.max', 'fwd_pkts_payload.tot',\n",
            "       'fwd_pkts_payload.avg', 'fwd_pkts_payload.std', 'bwd_pkts_payload.min',\n",
            "       'bwd_pkts_payload.max', 'bwd_pkts_payload.tot', 'bwd_pkts_payload.avg',\n",
            "       'bwd_pkts_payload.std', 'flow_pkts_payload.min',\n",
            "       'flow_pkts_payload.max', 'flow_pkts_payload.tot',\n",
            "       'flow_pkts_payload.avg', 'flow_pkts_payload.std', 'fwd_iat.min',\n",
            "       'fwd_iat.max', 'fwd_iat.tot', 'fwd_iat.avg', 'fwd_iat.std',\n",
            "       'bwd_iat.min', 'bwd_iat.max', 'bwd_iat.tot', 'bwd_iat.avg',\n",
            "       'bwd_iat.std', 'flow_iat.min', 'flow_iat.max', 'flow_iat.tot',\n",
            "       'flow_iat.avg', 'flow_iat.std', 'payload_bytes_per_second',\n",
            "       'fwd_subflow_pkts', 'bwd_subflow_pkts', 'fwd_subflow_bytes',\n",
            "       'bwd_subflow_bytes', 'fwd_bulk_bytes', 'bwd_bulk_bytes',\n",
            "       'fwd_bulk_packets', 'bwd_bulk_packets', 'fwd_bulk_rate',\n",
            "       'bwd_bulk_rate', 'active.min', 'active.max', 'active.tot', 'active.avg',\n",
            "       'active.std', 'idle.min', 'idle.max', 'idle.tot', 'idle.avg',\n",
            "       'idle.std', 'fwd_init_window_size', 'bwd_init_window_size',\n",
            "       'fwd_last_window_size', 'Attack_type'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1efbdc439a804ba0a5ba5f0ea2d115d3",
            "906e9908922243efa1255dc9f56200e9",
            "194ccbe51b92438ca911794e9a97da55",
            "6d60fd438eb94e48a28377e2eac3727d",
            "210f9c45d3b742eb8aec3331a1e819c6",
            "513c48528b9d41ddbf845d9afb366d66",
            "a174b9fa4bb249818e042fabad904e57",
            "81512f09b1b94e509d5a678105cd2c94",
            "abdb0afdd95547d6aa11cb2794af6114",
            "5e8247e29bf04bf8abf95a04a02d6c9f",
            "67923d04c9e249939e7dd1c7edd0b635",
            "120a45554d6c41fe9f7d86fec643e4bc",
            "2ba65c3152da4105947796b93fed0cc2",
            "4a46451305bd4cf4965e235a38a3ef82",
            "ff22e6eb0e5c4d2fab9fd0e95feb1fe9",
            "c8762fc40d8d4d4ebe3a35be5e3dba94"
          ]
        },
        "id": "7--GWBMIQKrO",
        "outputId": "6c89f00f-f47a-4056-de64-ee6188775eff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Button(button_style='success', description='Load Data', style=ButtonStyle()), Button(button_sty…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1efbdc439a804ba0a5ba5f0ea2d115d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mIoT data points after Splitting the Testing and Training data\n",
            "Training set shape:\n",
            "X_train: (86181, 94)\n",
            "y_train: (86181,)\n",
            "\n",
            "Testing set shape:\n",
            "X_test: (36936, 94)\n",
            "y_test: (36936,)\n",
            "Detecting threats...\n",
            "\u001b[1m1155/1155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m1155/1155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step\n",
            "Final predictions generated and threat detection completed\n",
            "Compliance Check Results: {'General Compliance': array([[ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True,  True, ...,  True, False,  True],\n",
            "       ...,\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True]]), 'GDPR Compliance': array([[ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True,  True, ...,  True, False,  True],\n",
            "       ...,\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True]]), 'CCPA Compliance': array([[ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True,  True, ...,  True, False,  True],\n",
            "       ...,\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True]]), 'NIST Compliance': array([[ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True,  True, ...,  True, False,  True],\n",
            "       ...,\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True]]), 'Overall Compliance': array([[ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True,  True, ...,  True, False,  True],\n",
            "       ...,\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True],\n",
            "       [ True,  True, False, ...,  True,  True,  True]])}\n",
            "General Compliance: 92.15% compliant\n",
            "GDPR Compliance: 91.85% compliant\n",
            "CCPA Compliance: 91.74% compliant\n",
            "NIST Compliance: 91.65% compliant\n",
            "Overall Compliance: 91.65% compliant\n",
            "Loaded Policies: {'Policy 1': 'Lawful Basis: Ensure all data collection and processing activities have a valid legal basis.', 'Policy 2': 'Minimization: Collect and process only the data necessary for the specified purposes.', 'Policy 3': 'Consent Management: Implement a robust system for obtaining and managing user consent.', 'Policy 4': 'Access and Portability: Allow users to access their data and receive it in a portable format.', 'Policy 5': 'Encryption: Implement strong encryption for data in transit and at rest.', 'Policy 6': 'Access Control: Enforce strict access controls and authentication mechanisms.', 'Policy 7': 'Vulnerability Management: Establish a process for identifying and addressing security vulnerabilities.', 'Policy 8': 'Vendor Assessment: Evaluate and monitor third-party vendors for privacy compliance.', 'Policy 9': 'Data Sharing Agreements: Implement formal agreements for any data sharing with third parties.', 'Policy 10': 'Algorithm Transparency: Provide explanations for AI-driven decisions affecting users.', 'Policy 11': 'Bias Mitigation: Regularly assess and mitigate potential biases in machine learning models.', 'Policy 12': 'Privacy Impact Assessments: Conduct regular assessments to identify and mitigate privacy risks.', 'Policy 13': 'Documentation: Maintain comprehensive records of privacy practices and data processing activities.', 'Policy 14': 'Auditing: Conduct regular audits of privacy practices and compliance measures.', 'Policy 15': 'Policy Updates: Regularly review and update privacy policies to reflect changes in data practices or regulations.'}\n",
            "\n",
            "Compliance Results: [False, True, True, True, True, False, True, True, True, True, True, False, True, True, False]\n",
            "Adjusted Policies: {'Policy 1': 'Adjust Policy: Lawful Basis: Ensure all data collection and processing activities have a valid legal basis. - Action Required', 'Policy 2': 'Minimization: Collect and process only the data necessary for the specified purposes. - No Policy Adjustment Needed.', 'Policy 3': 'Consent Management: Implement a robust system for obtaining and managing user consent. - No Policy Adjustment Needed.', 'Policy 4': 'Access and Portability: Allow users to access their data and receive it in a portable format. - No Policy Adjustment Needed.', 'Policy 5': 'Encryption: Implement strong encryption for data in transit and at rest. - No Policy Adjustment Needed.', 'Policy 6': 'Adjust Policy: Access Control: Enforce strict access controls and authentication mechanisms. - Action Required', 'Policy 7': 'Vulnerability Management: Establish a process for identifying and addressing security vulnerabilities. - No Policy Adjustment Needed.', 'Policy 8': 'Vendor Assessment: Evaluate and monitor third-party vendors for privacy compliance. - No Policy Adjustment Needed.', 'Policy 9': 'Data Sharing Agreements: Implement formal agreements for any data sharing with third parties. - No Policy Adjustment Needed.', 'Policy 10': 'Algorithm Transparency: Provide explanations for AI-driven decisions affecting users. - No Policy Adjustment Needed.', 'Policy 11': 'Bias Mitigation: Regularly assess and mitigate potential biases in machine learning models. - No Policy Adjustment Needed.', 'Policy 12': 'Adjust Policy: Privacy Impact Assessments: Conduct regular assessments to identify and mitigate privacy risks. - Action Required', 'Policy 13': 'Documentation: Maintain comprehensive records of privacy practices and data processing activities. - No Policy Adjustment Needed.', 'Policy 14': 'Auditing: Conduct regular audits of privacy practices and compliance measures. - No Policy Adjustment Needed.', 'Policy 15': 'Adjust Policy: Policy Updates: Regularly review and update privacy policies to reflect changes in data practices or regulations. - Action Required'}\n",
            "\n",
            "Initial Policies:\n",
            "  Policy 1: Lawful Basis: Ensure all data collection and processing activities have a valid legal basis.\n",
            "  Policy 2: Minimization: Collect and process only the data necessary for the specified purposes.\n",
            "  Policy 3: Consent Management: Implement a robust system for obtaining and managing user consent.\n",
            "  Policy 4: Access and Portability: Allow users to access their data and receive it in a portable format.\n",
            "  Policy 5: Encryption: Implement strong encryption for data in transit and at rest.\n",
            "  Policy 6: Access Control: Enforce strict access controls and authentication mechanisms.\n",
            "  Policy 7: Vulnerability Management: Establish a process for identifying and addressing security vulnerabilities.\n",
            "  Policy 8: Vendor Assessment: Evaluate and monitor third-party vendors for privacy compliance.\n",
            "  Policy 9: Data Sharing Agreements: Implement formal agreements for any data sharing with third parties.\n",
            "  Policy 10: Algorithm Transparency: Provide explanations for AI-driven decisions affecting users.\n",
            "  Policy 11: Bias Mitigation: Regularly assess and mitigate potential biases in machine learning models.\n",
            "  Policy 12: Privacy Impact Assessments: Conduct regular assessments to identify and mitigate privacy risks.\n",
            "  Policy 13: Documentation: Maintain comprehensive records of privacy practices and data processing activities.\n",
            "  Policy 14: Auditing: Conduct regular audits of privacy practices and compliance measures.\n",
            "  Policy 15: Policy Updates: Regularly review and update privacy policies to reflect changes in data practices or regulations.\n",
            "\n",
            "Adjusted Policies:\n",
            "  Policy 1: Adjust Policy: Lawful Basis: Ensure all data collection and processing activities have a valid legal basis. - Action Required\n",
            "  Policy 2: Minimization: Collect and process only the data necessary for the specified purposes. - No Policy Adjustment Needed.\n",
            "  Policy 3: Consent Management: Implement a robust system for obtaining and managing user consent. - No Policy Adjustment Needed.\n",
            "  Policy 4: Access and Portability: Allow users to access their data and receive it in a portable format. - No Policy Adjustment Needed.\n",
            "  Policy 5: Encryption: Implement strong encryption for data in transit and at rest. - No Policy Adjustment Needed.\n",
            "  Policy 6: Adjust Policy: Access Control: Enforce strict access controls and authentication mechanisms. - Action Required\n",
            "  Policy 7: Vulnerability Management: Establish a process for identifying and addressing security vulnerabilities. - No Policy Adjustment Needed.\n",
            "  Policy 8: Vendor Assessment: Evaluate and monitor third-party vendors for privacy compliance. - No Policy Adjustment Needed.\n",
            "  Policy 9: Data Sharing Agreements: Implement formal agreements for any data sharing with third parties. - No Policy Adjustment Needed.\n",
            "  Policy 10: Algorithm Transparency: Provide explanations for AI-driven decisions affecting users. - No Policy Adjustment Needed.\n",
            "  Policy 11: Bias Mitigation: Regularly assess and mitigate potential biases in machine learning models. - No Policy Adjustment Needed.\n",
            "  Policy 12: Adjust Policy: Privacy Impact Assessments: Conduct regular assessments to identify and mitigate privacy risks. - Action Required\n",
            "  Policy 13: Documentation: Maintain comprehensive records of privacy practices and data processing activities. - No Policy Adjustment Needed.\n",
            "  Policy 14: Auditing: Conduct regular audits of privacy practices and compliance measures. - No Policy Adjustment Needed.\n",
            "  Policy 15: Adjust Policy: Policy Updates: Regularly review and update privacy policies to reflect changes in data practices or regulations. - Action Required\n",
            "\n",
            "Enforcing Policy: Adjust Policy: Lawful Basis: Ensure all data collection and processing activities have a valid legal basis. - Action Required...\n",
            "Policy 2: No adjustment needed. Data is processed in compliance.\n",
            "Policy 3: No adjustment needed. Data is processed in compliance.\n",
            "Policy 4: No adjustment needed. Data is processed in compliance.\n",
            "Policy 5: No adjustment needed. Data is processed in compliance.\n",
            "Enforcing Policy: Adjust Policy: Access Control: Enforce strict access controls and authentication mechanisms. - Action Required...\n",
            "Policy 7: No adjustment needed. Data is processed in compliance.\n",
            "Policy 8: No adjustment needed. Data is processed in compliance.\n",
            "Policy 9: No adjustment needed. Data is processed in compliance.\n",
            "Policy 10: No adjustment needed. Data is processed in compliance.\n",
            "Policy 11: No adjustment needed. Data is processed in compliance.\n",
            "Enforcing Policy: Adjust Policy: Privacy Impact Assessments: Conduct regular assessments to identify and mitigate privacy risks. - Action Required...\n",
            "Policy 13: No adjustment needed. Data is processed in compliance.\n",
            "Policy 14: No adjustment needed. Data is processed in compliance.\n",
            "Enforcing Policy: Adjust Policy: Policy Updates: Regularly review and update privacy policies to reflect changes in data practices or regulations. - Action Required...\n",
            "ALERT: Threats detected. Adjust Policy: Lawful Basis: Ensure all data collection and processing activities have a valid legal basis. - Action Required\n",
            "Policy 2 is compliant and can continue processing data.\n",
            "Policy 3 is compliant and can continue processing data.\n",
            "Policy 4 is compliant and can continue processing data.\n",
            "Policy 5 is compliant and can continue processing data.\n",
            "ALERT: Threats detected. Adjust Policy: Access Control: Enforce strict access controls and authentication mechanisms. - Action Required\n",
            "Policy 7 is compliant and can continue processing data.\n",
            "Policy 8 is compliant and can continue processing data.\n",
            "Policy 9 is compliant and can continue processing data.\n",
            "Policy 10 is compliant and can continue processing data.\n",
            "Policy 11 is compliant and can continue processing data.\n",
            "ALERT: Threats detected. Adjust Policy: Privacy Impact Assessments: Conduct regular assessments to identify and mitigate privacy risks. - Action Required\n",
            "Policy 13 is compliant and can continue processing data.\n",
            "Policy 14 is compliant and can continue processing data.\n",
            "ALERT: Threats detected. Adjust Policy: Policy Updates: Regularly review and update privacy policies to reflect changes in data practices or regulations. - Action Required\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
        "from docx import Document\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Widgets for interaction\n",
        "load_button = widgets.Button(description=\"Load Data\", button_style='success')\n",
        "check_compliance_button = widgets.Button(description=\"Check Compliance\", button_style='primary')\n",
        "adjust_button = widgets.Button(description=\"Adjust Policies\", button_style='danger')\n",
        "enforce_button = widgets.Button(description=\"Enforce Policies\", button_style='warning')\n",
        "\n",
        "# Outputing widget to display results\n",
        "output = widgets.Output()\n",
        "\n",
        "# Displaying the interface i.e. buttons\n",
        "display(widgets.VBox([load_button, check_compliance_button, adjust_button, enforce_button, output]))\n",
        "\n",
        "# Global variables that stores data and models\n",
        "data = None\n",
        "X_preprocessed = None\n",
        "Y = None\n",
        "X_train = X_test = y_train = y_test = None\n",
        "cnn_model = None\n",
        "lstm_model = None\n",
        "X_train_reshaped = X_test_reshaped = None\n",
        "compliance_results = None\n",
        "policies = None\n",
        "adjusted_policies = None\n",
        "\n",
        "# Loading and preprocessing the data\n",
        "def load_data(b=None):\n",
        "    global data, X_preprocessed, Y, X_train, X_test, y_train, y_test\n",
        "    with output:\n",
        "        #output.clear_output()\n",
        "        print(\"Loading data.....\")\n",
        "        try:\n",
        "            # Loads the dataset\n",
        "            data = pd.read_csv('/content/drive/MyDrive/RT_IOT2022.csv')\n",
        "\n",
        "            # Creating a 'time' column based on the dataset length\n",
        "            data['time'] = pd.date_range(start='2022-01-01 00:00', periods=len(data), freq='T')\n",
        "\n",
        "            # Seting 'time' as index\n",
        "            data.set_index('time', inplace=True)\n",
        "\n",
        "            print(\"Dataset loaded successfully.\")\n",
        "            print(\"Displaying first few rows:\")\n",
        "            display(data.head())\n",
        "\n",
        "            # Droping irrelevant columns\n",
        "            data.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "            # Defining target variable\n",
        "            Y = data['Attack_type']\n",
        "            X = data.drop(columns=['Attack_type'])\n",
        "\n",
        "            # Identifying numerical and categorical columns\n",
        "            categorical_features = ['proto', 'service']\n",
        "            numeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "            numeric_features = [col for col in numeric_features if col not in categorical_features]\n",
        "\n",
        "            # Preprocessor: Scaling numeric data and encoding categorical data\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[\n",
        "                    ('num', StandardScaler(), numeric_features),\n",
        "                    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "                ], remainder='drop')\n",
        "\n",
        "            # Applying preprocessing to the dataset\n",
        "            X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "            # Having additional Scaling\n",
        "            scaler = MinMaxScaler()\n",
        "            X_preprocessed = scaler.fit_transform(X_preprocessed)\n",
        "\n",
        "            print(\"Data is preprocessed successfully.\")\n",
        "\n",
        "            # Encoding target variable\n",
        "            label_encoder = LabelEncoder()\n",
        "            Y_encoded = label_encoder.fit_transform(Y)\n",
        "            print(\"Target variable encoded.\")\n",
        "\n",
        "            # Train-test split section, Test Data = 30%\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_preprocessed, Y_encoded, test_size=0.3, random_state=42, stratify=Y_encoded\n",
        "            )\n",
        "            print(\"Train-test split done successfully.\")\n",
        "            print(f\"Training set size: {X_train.shape[0]}\")\n",
        "            print(f\"Testing set size: {X_test.shape[0]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "\n",
        "# Reshaping data for CNN and LSTM\n",
        "def reshape_data(X_train, X_test):\n",
        "    X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "    return X_train_reshaped, X_test_reshaped\n",
        "\n",
        "# Defining and training the CNN Model\n",
        "def train_cnn_model():\n",
        "    global cnn_model, X_train_reshaped, X_test_reshaped\n",
        "    with output:\n",
        "        #output.clear_output()\n",
        "        if X_train is None or y_train is None:\n",
        "            print(\"Please load the data first.\")\n",
        "            return\n",
        "        print(\"Reshaping data for CNN...\")\n",
        "        try:\n",
        "            X_train_reshaped, X_test_reshaped = reshape_data(X_train, X_test)\n",
        "            print(\"Data reshaped successfully.\")\n",
        "\n",
        "            print(\"Training CNN Model...\")\n",
        "            cnn_model = Sequential([\n",
        "                Conv1D(32, 3, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)),\n",
        "                MaxPooling1D(2),\n",
        "                Conv1D(64, 3, activation='relu'),\n",
        "                MaxPooling1D(2),\n",
        "                Flatten(),\n",
        "                Dense(64, activation='relu'),\n",
        "                Dense(len(np.unique(y_train)), activation='softmax')\n",
        "            ])\n",
        "            cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "            cnn_model.fit(\n",
        "                X_train_reshaped, y_train,\n",
        "                epochs=5,\n",
        "                batch_size=32,\n",
        "                validation_data=(X_test_reshaped, y_test),\n",
        "                callbacks=[early_stopping],\n",
        "                verbose=2\n",
        "            )\n",
        "            print(\"CNN Model trained successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error training CNN model: {e}\")\n",
        "\n",
        "# Defining and training the LSTM Model\n",
        "def train_lstm_model():\n",
        "    global lstm_model\n",
        "    with output:\n",
        "        #output.clear_output()\n",
        "        if X_train_reshaped is None or y_train is None:\n",
        "            print(\"Please load the data and train CNN model first.\")\n",
        "            return\n",
        "        print(\"Training LSTM Model...\")\n",
        "        try:\n",
        "            lstm_model = Sequential([\n",
        "                LSTM(50, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)),\n",
        "                Dropout(0.2),\n",
        "                LSTM(50, return_sequences=False),\n",
        "                Dropout(0.2),\n",
        "                Dense(len(np.unique(y_train)), activation='softmax')\n",
        "            ])\n",
        "            lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "            lstm_model.fit(\n",
        "                X_train_reshaped, y_train,\n",
        "                epochs=2,\n",
        "                batch_size=32,\n",
        "                validation_data=(X_test_reshaped, y_test),\n",
        "                callbacks=[early_stopping],\n",
        "                verbose=2\n",
        "            )\n",
        "            print(\"LSTM Model trained successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error training LSTM model: {e}\")\n",
        "\n",
        "# Detecting threats using CNN and LSTM models\n",
        "def detect_threats(cnn_model, lstm_model, X_test, threshold=0.5):\n",
        "    print(\"Detecting threats...\")\n",
        "    cnn_predictions = cnn_model.predict(X_test)\n",
        "    lstm_predictions = lstm_model.predict(X_test)\n",
        "\n",
        "    final_predictions = (cnn_predictions + lstm_predictions) / 2\n",
        "    threats = final_predictions > threshold\n",
        "    print(\"Final predictions generated and threat detection completed\")\n",
        "    return threats, final_predictions\n",
        "\n",
        "# Compliance checking against regulatory compliance (GDPR, CCPA, NIST)\n",
        "def regulatory_compliance_check(threats, predictions):\n",
        "    # Compute compliance based on thresholds\n",
        "    general_compliance = predictions < 0.7\n",
        "    gdpr_compliance = predictions < 0.6\n",
        "    ccpa_compliance = predictions < 0.5\n",
        "    nist_compliance = predictions < 0.4\n",
        "    overall_compliance = general_compliance & gdpr_compliance & ccpa_compliance & nist_compliance\n",
        "\n",
        "    # Returns the compliance as percentages against whats outputs from its threshold\n",
        "    return {\n",
        "        \"General Compliance\": general_compliance,\n",
        "        \"GDPR Compliance\": gdpr_compliance,\n",
        "        \"CCPA Compliance\": ccpa_compliance,\n",
        "        \"NIST Compliance\": nist_compliance,\n",
        "        \"Overall Compliance\": overall_compliance\n",
        "    }\n",
        "\n",
        "def process_compliance_results(compliance_results):\n",
        "    for standard, results in compliance_results.items():\n",
        "        # Calculates compliance percentage correctly\n",
        "        compliant_count = np.sum(results)  # Counts the number of True values\n",
        "        total_count = results.size  # Total number of elements\n",
        "        compliance_percentage = (compliant_count / total_count) * 100  # Calculates its percentage now\n",
        "        print(f\"{standard}: {compliance_percentage:.2f}% compliant\")\n",
        "\n",
        "# Compliance checking function\n",
        "def check_compliance(b=None):\n",
        "    with output:\n",
        "        #output.clear_output()\n",
        "        global compliance_results\n",
        "        if cnn_model is None or lstm_model is None:\n",
        "            print(\"Please train the models first.\")\n",
        "            return\n",
        "        print(\"Checking compliance...\")\n",
        "\n",
        "        # Uses the final predictions for compliance checking\n",
        "        threats, predictions = detect_threats(cnn_model, lstm_model, X_test_reshaped)\n",
        "        if predictions is None:\n",
        "            print(\"Error during threat detection.\")\n",
        "            return\n",
        "\n",
        "        compliance_results = regulatory_compliance_check(predictions)\n",
        "        process_compliance_results(compliance_results)\n",
        "        print(f\"Compliance Results: {compliance_results}\")\n",
        "\n",
        "# Binding widget buttons to their functions\n",
        "load_button.on_click(load_data)\n",
        "check_compliance_button.on_click(check_compliance)\n",
        "\n",
        "# Loads, Adjusts, and Saves Policies from its docx documents\n",
        "def load_policies(doc_path):\n",
        "    doc = Document(doc_path)\n",
        "    policies = {}\n",
        "    for para in doc.paragraphs:\n",
        "        if para.text and \":\" in para.text:\n",
        "            key_value = para.text.split(\":\", 1)\n",
        "            if len(key_value) == 2:\n",
        "                key, value = key_value\n",
        "                policies[key.strip()] = value.strip()\n",
        "            else:\n",
        "                policies[key_value[0].strip()] = \"\"\n",
        "        elif para.text:# Handles paragraphs without a colon\n",
        "              policies[para.text.strip()] = \"\"\n",
        "              #print(policies)\n",
        "    return policies\n",
        "\n",
        "def save_policies(policies, doc_path):\n",
        "    doc = Document()\n",
        "    doc.add_heading(\"Adjusted Policies\", level=1)\n",
        "    for key, value in policies.items():\n",
        "        doc.add_paragraph(f\"{key}: {value}\")\n",
        "    doc.save(doc_path)\n",
        "\n",
        "def adjust_policies(policies, compliance_results):\n",
        "    adjusted_policies = {}\n",
        "    for i, (policy, compliant) in enumerate(zip(policies.items(), compliance_results)):\n",
        "        key, value = policy\n",
        "        if not compliant:\n",
        "            adjusted_policies[key] = f\"Adjust Policy: {value} - Action Required\"\n",
        "        else:\n",
        "            adjusted_policies[key] = f\"{value} - No Policy Adjustment Needed.\"\n",
        "    save_policies(adjusted_policies, \"/content/drive/MyDrive/AdjustedPolicies.docx\")\n",
        "    return adjusted_policies\n",
        "\n",
        "# Each policy displayed on a new line for easy stucture\n",
        "def print_policies(policies, title=\"Policies\"):\n",
        "    print(f\"{title}:\")\n",
        "    for key, value in policies.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    print()  # New lines for better separation\n",
        "\n",
        "# Enforces policies\n",
        "def enforce_policies(policies):\n",
        "    for policy, action in policies.items():\n",
        "        if \"Adjust Policy\" in action:\n",
        "            print(f\"Enforcing Policy: {action}...\")\n",
        "        else:\n",
        "            print(f\"{policy}: No adjustment needed. Data is processed in compliance.\")\n",
        "\n",
        "# Alert mechanism\n",
        "def send_alert(message):\n",
        "    print(f\"ALERT: {message}\")\n",
        "\n",
        "adjust_button.on_click(adjust_policies)\n",
        "enforce_button.on_click(enforce_policies)\n",
        "\n",
        "# Main function to execute everything\n",
        "def main():\n",
        "    # Loads the data\n",
        "    load_data()\n",
        "    # Printing statement of testing and training data is split\n",
        "    print(\"\\033[1m\" + \"IoT data points after Splitting the Testing and Training data\")\n",
        "    print(\"Training set shape:\")\n",
        "    print(f\"X_train: {X_train.shape}\")\n",
        "    print(f\"y_train: {y_train.shape}\")\n",
        "    print(\"\\nTesting set shape:\")\n",
        "    print(f\"X_test: {X_test.shape}\")\n",
        "    print(f\"y_test: {y_test.shape}\")\n",
        "    # Reshape data for CNN and LSTM\n",
        "    global X_train_reshaped, X_test_reshaped  # Declared as global to avoid issues\n",
        "    X_train_reshaped, X_test_reshaped = reshape_data(X_train, X_test)\n",
        "    # Train the models\n",
        "    train_cnn_model()\n",
        "    train_lstm_model()\n",
        "    # Detect threats (cnn_model and lstm_model are also set globally)\n",
        "    threats, predictions = detect_threats(cnn_model, lstm_model, X_test_reshaped)\n",
        "    # Compliance check\n",
        "    compliance_results = regulatory_compliance_check(threats=None, predictions=predictions)\n",
        "    print(\"Compliance Check Results:\", compliance_results)\n",
        "    process_compliance_results(compliance_results)\n",
        "    policies_file_path = \"/content/drive/MyDrive/Policies.docx\"\n",
        "    initial_policies = load_policies(policies_file_path)\n",
        "    print(f\"Loaded Policies: {initial_policies}\\n\")\n",
        "    compliance_results = [random.choice([True, False]) for _ in range(len(initial_policies))]\n",
        "    print(f\"Compliance Results: {compliance_results}\")\n",
        "    adjusted_policies = adjust_policies(initial_policies, compliance_results)\n",
        "    print(f\"Adjusted Policies: {adjusted_policies}\\n\")\n",
        "    print_policies(initial_policies, \"Initial Policies\")\n",
        "    print_policies(adjusted_policies, \"Adjusted Policies\")\n",
        "    enforce_policies(adjusted_policies)\n",
        "    # Sending alerts for non-compliance and based on policy adjustments\n",
        "    for policy, action in adjusted_policies.items():\n",
        "        if \"Adjust Policy\" in action:\n",
        "            send_alert(f\"Threats detected. {action}\")\n",
        "        else:\n",
        "            print(f\"{policy} is compliant and can continue processing data.\")\n",
        "\n",
        "# Execute main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}